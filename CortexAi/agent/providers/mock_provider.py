import random
import re
from typing import Union, List, Dict, Optional

from CortexAi.agent.providers.base_provider import BaseProvider


class MockProvider(BaseProvider):
    """
    A mock provider for testing/demos without requiring API keys.

    This provider randomly decides whether to call a tool or
    return a direct answer. It's useful for testing agent logic
    and flow without incurring costs from real API calls.
    """

    is_chat_model = False

    def __init__(self, seed: Optional[int] = None):
        """
        Initialize the mock provider with an optional random seed.

        Args:
            seed: Optional integer seed for random number generator (for reproducibility)
        """
        if seed is not None:
            random.seed(seed)

        self.responses = [
            "This is a mock response. In a real system, this would be generated by an LLM.",
            "I would recommend researching that topic further to get more comprehensive information.",
            "Based on the available information, I can't provide a definitive answer.",
            "Let me analyze that for you... The key insights are: 1) data shows trends, 2) multiple factors involved."
        ]

        self.tool_calls = {
            "ScraperTool": "[UseTool:ScraperTool url=https://example.com]",
            "FileReaderTool": "[UseTool:FileReaderTool file_path=\"/path/to/sample.txt\"]",
            "FileWriterTool": "[UseTool:FileWriterTool file_path=\"/path/to/output.txt\" content=\"Sample content\" mode=\"w\"]",
            "PythonExecutorTool": "[UseTool:PythonExecutorTool code=\"print('Hello world')\"]",
            "WebSearchTool": "[UseTool:WebSearchTool query=\"search query\" num_results=5]",
        }

    async def generate_async(
        self,
        prompt: Union[str, List[Dict[str, str]]],
        **kwargs
    ) -> str:
        """
        Generate a mock response based on the prompt.

        Args:
            prompt: String prompt or list of message dictionaries
            **kwargs: Additional parameters (ignored)

        Returns:
            A predefined or random mock response
        """
        if isinstance(prompt, list):
            combined = "\n".join([f"{m['role']}: {m['content']}" for m in prompt])
        else:
            combined = prompt

        # Check for direct tool usage instructions
        tool_patterns = {
            "FileReaderTool": r'FileReaderTool.*?file_path\s*=\s*["\']?([^"\']+)["\']?',
            "FileWriterTool": r'FileWriterTool.*?file_path\s*=\s*["\']?([^"\']+)["\']?',
            "PythonExecutorTool": r'PythonExecutorTool.*?code\s*=',
            "WebSearchTool": r'WebSearchTool.*?query\s*=',
            "ScraperTool": r'ScraperTool.*?url\s*='
        }
        
        for tool_name, pattern in tool_patterns.items():
            if re.search(pattern, combined, re.IGNORECASE):
                # For FileReaderTool and FileWriterTool, extract and use the actual file path
                if tool_name in ["FileReaderTool", "FileWriterTool"]:
                    match = re.search(pattern, combined, re.IGNORECASE)
                    if match and tool_name == "FileReaderTool":
                        file_path = match.group(1)
                        return f'[UseTool:FileReaderTool file_path="{file_path}"]'
                    elif match and tool_name == "FileWriterTool":
                        file_path = match.group(1)
                        if "mode=\"a\"" in combined or "mode='a'" in combined:
                            content = "'Line 4: This line was added by the FileWriterTool.'"
                            return f'[UseTool:FileWriterTool file_path="{file_path}" content={content} mode="a"]'
                        else:
                            return f'[UseTool:FileWriterTool file_path="{file_path}" content="New content" mode="w"]'
                
                # Return the appropriate tool call template
                return self.tool_calls[tool_name]

        # Fallback to generic behavior
        tool_keywords = ["search", "find", "lookup", "get", "scrape", "download", "query", "analyze", "read", "write", "execute"]
        has_tool_keyword = any(keyword in combined.lower() for keyword in tool_keywords)

        if "UseTool" in combined or (has_tool_keyword and random.random() < 0.7):
            words = combined.split()
            urls = [w for w in words if w.startswith("http")]

            if urls and random.random() < 0.8:
                return f"[UseTool:ScraperTool url={urls[0]}]"
            else:
                return random.choice(list(self.tool_calls.values()))
        else:
            if "plan" in combined.lower() and random.random() < 0.7:
                return self._generate_mock_plan()
            else:
                return random.choice(self.responses)

    def _generate_mock_plan(self) -> str:
        """Generate a mock planning response with structured JSON"""
        return """
        I'll break this task down into logical steps:

        ```json
        [
          {"description": "Analyze requirements and gather necessary information"},
          {"description": "Design the solution architecture"},
          {"description": "Implement core functionality"},
          {"description": "Test the implementation and fix any issues"},
          {"description": "Deploy and validate the final solution"}
        ]
        ```

        This plan provides a structured approach to accomplishing your goal.
        """

    async def get_embedding(self, text: str) -> List[float]:
        """
        Generate a mock embedding vector.

        Args:
            text: The text to embed

        Returns:
            A random embedding vector of length 10
        """
        seed_val = sum(ord(c) for c in text)
        random.seed(seed_val)

        embedding = [random.uniform(-1, 1) for _ in range(10)]

        random.seed()

        return embedding

    def num_tokens(self, text: str) -> int:
        """
        Estimate token count in a very simplistic way.

        Args:
            text: The text to count tokens for

        Returns:
            Approximate token count
        """
        words = text.split()
        return len(words) + int(len(text) * 0.1)
